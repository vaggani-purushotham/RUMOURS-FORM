{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a96cfb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:49.724318Z",
     "iopub.status.busy": "2024-12-23T03:48:49.724070Z",
     "iopub.status.idle": "2024-12-23T03:48:55.890063Z",
     "shell.execute_reply": "2024-12-23T03:48:55.889206Z"
    },
    "papermill": {
     "duration": 6.176354,
     "end_time": "2024-12-23T03:48:55.891464",
     "exception": false,
     "start_time": "2024-12-23T03:48:49.715110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt \n",
    "import transformers\n",
    "import random\n",
    "import chardet\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "scaler = torch.cuda.amp.GradScaler() \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d4403cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:55.905680Z",
     "iopub.status.busy": "2024-12-23T03:48:55.905303Z",
     "iopub.status.idle": "2024-12-23T03:48:55.914427Z",
     "shell.execute_reply": "2024-12-23T03:48:55.913603Z"
    },
    "papermill": {
     "duration": 0.017423,
     "end_time": "2024-12-23T03:48:55.915635",
     "exception": false,
     "start_time": "2024-12-23T03:48:55.898212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_seed(SEED):\n",
    "    \n",
    "    random.seed(SEED)\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    \n",
    "SEED = 508\n",
    "random_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cc1baf0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:55.929716Z",
     "iopub.status.busy": "2024-12-23T03:48:55.929510Z",
     "iopub.status.idle": "2024-12-23T03:48:55.977522Z",
     "shell.execute_reply": "2024-12-23T03:48:55.976749Z"
    },
    "papermill": {
     "duration": 0.056405,
     "end_time": "2024-12-23T03:48:55.978659",
     "exception": false,
     "start_time": "2024-12-23T03:48:55.922254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>üî•ca kkk grand wizard üî• endorses @hillaryclinto...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances ‚Äî@potus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>692004901455556608</td>\n",
       "      <td>.@potus just announced new reforms to address ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>760109079133990912</td>\n",
       "      <td>‚Äúafter school satan clubs‚Äù? URL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>500281131057811456</td>\n",
       "      <td>breaking news: according to documents released...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>523098334421319680</td>\n",
       "      <td>ebola vaccines? URL #news #today</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>523545090099523584</td>\n",
       "      <td>concerned airport passenger suits up in homema...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                                               text\n",
       "0     731166399389962242  üî•ca kkk grand wizard üî• endorses @hillaryclinto...\n",
       "1     714598641827246081  an open letter to trump voters from his top st...\n",
       "2     691809004356501505  america is a nation of second chances ‚Äî@potus ...\n",
       "3     693204708933160960  brandon marshall visits and offers advice, sup...\n",
       "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...\n",
       "...                  ...                                                ...\n",
       "1485  692004901455556608  .@potus just announced new reforms to address ...\n",
       "1486  760109079133990912                    ‚Äúafter school satan clubs‚Äù? URL\n",
       "1487  500281131057811456  breaking news: according to documents released...\n",
       "1488  523098334421319680                   ebola vaccines? URL #news #today\n",
       "1489  523545090099523584  concerned airport passenger suits up in homema...\n",
       "\n",
       "[1490 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unverified</td>\n",
       "      <td>731166399389962242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unverified</td>\n",
       "      <td>714598641827246081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>non-rumor</td>\n",
       "      <td>691809004356501505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>non-rumor</td>\n",
       "      <td>693204708933160960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>true</td>\n",
       "      <td>551099691702956032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>non-rumor</td>\n",
       "      <td>692004901455556608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>unverified</td>\n",
       "      <td>760109079133990912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>unverified</td>\n",
       "      <td>500281131057811456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>false</td>\n",
       "      <td>523098334421319680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>unverified</td>\n",
       "      <td>523545090099523584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows √ó 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           label                  ID\n",
       "0     unverified  731166399389962242\n",
       "1     unverified  714598641827246081\n",
       "2      non-rumor  691809004356501505\n",
       "3      non-rumor  693204708933160960\n",
       "4           true  551099691702956032\n",
       "...          ...                 ...\n",
       "1485   non-rumor  692004901455556608\n",
       "1486  unverified  760109079133990912\n",
       "1487  unverified  500281131057811456\n",
       "1488       false  523098334421319680\n",
       "1489  unverified  523545090099523584\n",
       "\n",
       "[1490 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data0=pd.read_csv('/kaggle/input/rumor-detection-acl-2017/twitter15/source_tweets.txt',sep=\"\\t\", header=None, names=[\"ID\", \"text\"])\n",
    "label0=pd.read_csv('/kaggle/input/rumor-detection-acl-2017/twitter15/label.txt',sep=\":\", header=None, names=[\"label\",'ID'])\n",
    "display(data0)\n",
    "display(label0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70c55082",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:55.993484Z",
     "iopub.status.busy": "2024-12-23T03:48:55.993252Z",
     "iopub.status.idle": "2024-12-23T03:48:56.020305Z",
     "shell.execute_reply": "2024-12-23T03:48:56.019590Z"
    },
    "papermill": {
     "duration": 0.035689,
     "end_time": "2024-12-23T03:48:56.021555",
     "exception": false,
     "start_time": "2024-12-23T03:48:55.985866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>üî•ca kkk grand wizard üî• endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances ‚Äî@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>692004901455556608</td>\n",
       "      <td>.@potus just announced new reforms to address ...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>760109079133990912</td>\n",
       "      <td>‚Äúafter school satan clubs‚Äù? URL</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>500281131057811456</td>\n",
       "      <td>breaking news: according to documents released...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>523098334421319680</td>\n",
       "      <td>ebola vaccines? URL #news #today</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>523545090099523584</td>\n",
       "      <td>concerned airport passenger suits up in homema...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                                               text  \\\n",
       "0     731166399389962242  üî•ca kkk grand wizard üî• endorses @hillaryclinto...   \n",
       "1     714598641827246081  an open letter to trump voters from his top st...   \n",
       "2     691809004356501505  america is a nation of second chances ‚Äî@potus ...   \n",
       "3     693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "...                  ...                                                ...   \n",
       "1485  692004901455556608  .@potus just announced new reforms to address ...   \n",
       "1486  760109079133990912                    ‚Äúafter school satan clubs‚Äù? URL   \n",
       "1487  500281131057811456  breaking news: according to documents released...   \n",
       "1488  523098334421319680                   ebola vaccines? URL #news #today   \n",
       "1489  523545090099523584  concerned airport passenger suits up in homema...   \n",
       "\n",
       "           label  \n",
       "0     unverified  \n",
       "1     unverified  \n",
       "2      non-rumor  \n",
       "3      non-rumor  \n",
       "4           true  \n",
       "...          ...  \n",
       "1485   non-rumor  \n",
       "1486  unverified  \n",
       "1487  unverified  \n",
       "1488       false  \n",
       "1489  unverified  \n",
       "\n",
       "[1490 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = pd.merge(data0, label0, on=\"ID\", how=\"left\")\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77eedf5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:56.036800Z",
     "iopub.status.busy": "2024-12-23T03:48:56.036601Z",
     "iopub.status.idle": "2024-12-23T03:48:56.053284Z",
     "shell.execute_reply": "2024-12-23T03:48:56.052596Z"
    },
    "papermill": {
     "duration": 0.025726,
     "end_time": "2024-12-23T03:48:56.054531",
     "exception": false,
     "start_time": "2024-12-23T03:48:56.028805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>text</th>\n",
       "      <th>targets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>731166399389962242</td>\n",
       "      <td>üî•ca kkk grand wizard üî• endorses @hillaryclinto...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>714598641827246081</td>\n",
       "      <td>an open letter to trump voters from his top st...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>691809004356501505</td>\n",
       "      <td>america is a nation of second chances ‚Äî@potus ...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693204708933160960</td>\n",
       "      <td>brandon marshall visits and offers advice, sup...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>551099691702956032</td>\n",
       "      <td>rip elly may clampett: so sad to learn #beverl...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>692004901455556608</td>\n",
       "      <td>.@potus just announced new reforms to address ...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>760109079133990912</td>\n",
       "      <td>‚Äúafter school satan clubs‚Äù? URL</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1487</th>\n",
       "      <td>500281131057811456</td>\n",
       "      <td>breaking news: according to documents released...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1488</th>\n",
       "      <td>523098334421319680</td>\n",
       "      <td>ebola vaccines? URL #news #today</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1489</th>\n",
       "      <td>523545090099523584</td>\n",
       "      <td>concerned airport passenger suits up in homema...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1490 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      ID                                               text  \\\n",
       "0     731166399389962242  üî•ca kkk grand wizard üî• endorses @hillaryclinto...   \n",
       "1     714598641827246081  an open letter to trump voters from his top st...   \n",
       "2     691809004356501505  america is a nation of second chances ‚Äî@potus ...   \n",
       "3     693204708933160960  brandon marshall visits and offers advice, sup...   \n",
       "4     551099691702956032  rip elly may clampett: so sad to learn #beverl...   \n",
       "...                  ...                                                ...   \n",
       "1485  692004901455556608  .@potus just announced new reforms to address ...   \n",
       "1486  760109079133990912                    ‚Äúafter school satan clubs‚Äù? URL   \n",
       "1487  500281131057811456  breaking news: according to documents released...   \n",
       "1488  523098334421319680                   ebola vaccines? URL #news #today   \n",
       "1489  523545090099523584  concerned airport passenger suits up in homema...   \n",
       "\n",
       "         targets  \n",
       "0     unverified  \n",
       "1     unverified  \n",
       "2      non-rumor  \n",
       "3      non-rumor  \n",
       "4           true  \n",
       "...          ...  \n",
       "1485   non-rumor  \n",
       "1486  unverified  \n",
       "1487  unverified  \n",
       "1488       false  \n",
       "1489  unverified  \n",
       "\n",
       "[1490 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['false', 'non-rumor', 'true', 'unverified']\n"
     ]
    }
   ],
   "source": [
    "data.columns=['ID','text','targets']\n",
    "display(data)\n",
    "classes=sorted(data['targets'].unique().tolist())\n",
    "print(classes)\n",
    "class_names=['false', 'non-rumor', 'true', 'unverified']\n",
    "N=list(range(len(class_names)))\n",
    "normal_mapping=dict(zip(class_names,N)) \n",
    "reverse_mapping=dict(zip(N,class_names))       \n",
    "data['targets']=data['targets'].map(normal_mapping)  \n",
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "648929a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:56.069865Z",
     "iopub.status.busy": "2024-12-23T03:48:56.069649Z",
     "iopub.status.idle": "2024-12-23T03:48:56.075678Z",
     "shell.execute_reply": "2024-12-23T03:48:56.074768Z"
    },
    "papermill": {
     "duration": 0.015043,
     "end_time": "2024-12-23T03:48:56.077017",
     "exception": false,
     "start_time": "2024-12-23T03:48:56.061974",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490\n"
     ]
    }
   ],
   "source": [
    "print(len(data))\n",
    "data=data.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0c8f4ad8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:56.093124Z",
     "iopub.status.busy": "2024-12-23T03:48:56.092843Z",
     "iopub.status.idle": "2024-12-23T03:48:56.097825Z",
     "shell.execute_reply": "2024-12-23T03:48:56.096986Z"
    },
    "papermill": {
     "duration": 0.013963,
     "end_time": "2024-12-23T03:48:56.099005",
     "exception": false,
     "start_time": "2024-12-23T03:48:56.085042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6847dd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:56.114520Z",
     "iopub.status.busy": "2024-12-23T03:48:56.114293Z",
     "iopub.status.idle": "2024-12-23T03:48:57.863315Z",
     "shell.execute_reply": "2024-12-23T03:48:57.862566Z"
    },
    "papermill": {
     "duration": 1.758352,
     "end_time": "2024-12-23T03:48:57.864976",
     "exception": false,
     "start_time": "2024-12-23T03:48:56.106624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b93821c7212d4084ade0dbbd0de42eca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7846800b399b4fe0bf6646c556419a2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad2a4875ea449f1b33e33026229a370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62878946f13c478b9aa090efe62cf7d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9dfca9edf84560a731a30e0de9b96f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e3cf851e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:57.883255Z",
     "iopub.status.busy": "2024-12-23T03:48:57.882979Z",
     "iopub.status.idle": "2024-12-23T03:48:57.886141Z",
     "shell.execute_reply": "2024-12-23T03:48:57.885304Z"
    },
    "papermill": {
     "duration": 0.01346,
     "end_time": "2024-12-23T03:48:57.887403",
     "exception": false,
     "start_time": "2024-12-23T03:48:57.873943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#tokenizer = transformers.BertTokenizer.from_pretrained(\"../input/bert-base-uncased\")\n",
    "#tokenizer = transformers.RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dd59e2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:48:57.905015Z",
     "iopub.status.busy": "2024-12-23T03:48:57.904739Z",
     "iopub.status.idle": "2024-12-23T03:49:06.160272Z",
     "shell.execute_reply": "2024-12-23T03:49:06.159404Z"
    },
    "papermill": {
     "duration": 8.26589,
     "end_time": "2024-12-23T03:49:06.161640",
     "exception": false,
     "start_time": "2024-12-23T03:48:57.895750",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>meet the south american goliath birdeater -- a spider the size of a puppy: URL URL</s>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_s = train['text'].iloc[0]\n",
    "result1 = tokenizer.encode_plus(test_s)\n",
    "tokenizer.decode(result1[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff1e0d15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.179432Z",
     "iopub.status.busy": "2024-12-23T03:49:06.178999Z",
     "iopub.status.idle": "2024-12-23T03:49:06.183585Z",
     "shell.execute_reply": "2024-12-23T03:49:06.182967Z"
    },
    "papermill": {
     "duration": 0.014459,
     "end_time": "2024-12-23T03:49:06.184723",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.170264",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_s.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6dfc58f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.201262Z",
     "iopub.status.busy": "2024-12-23T03:49:06.201052Z",
     "iopub.status.idle": "2024-12-23T03:49:06.204612Z",
     "shell.execute_reply": "2024-12-23T03:49:06.204038Z"
    },
    "papermill": {
     "duration": 0.013078,
     "end_time": "2024-12-23T03:49:06.205747",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.192669",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "result2 = tokenizer.encode_plus(\n",
    "    test_s,\n",
    "    add_special_tokens = True, \n",
    "    max_length = 8, \n",
    "    pad_to_max_length = True, \n",
    "    truncation = True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "febb7009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.222685Z",
     "iopub.status.busy": "2024-12-23T03:49:06.222434Z",
     "iopub.status.idle": "2024-12-23T03:49:06.226869Z",
     "shell.execute_reply": "2024-12-23T03:49:06.226134Z"
    },
    "papermill": {
     "duration": 0.014066,
     "end_time": "2024-12-23T03:49:06.228033",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.213967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>meet the south american g</s>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(result2[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "50fd1f9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.244647Z",
     "iopub.status.busy": "2024-12-23T03:49:06.244426Z",
     "iopub.status.idle": "2024-12-23T03:49:06.253648Z",
     "shell.execute_reply": "2024-12-23T03:49:06.252712Z"
    },
    "papermill": {
     "duration": 0.018831,
     "end_time": "2024-12-23T03:49:06.254917",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.236086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sens = 8\n",
    "train = train.sort_values('targets').reset_index(drop=True)\n",
    "train[\"kfold\"] = train.index % 5\n",
    "p_train = train[train[\"kfold\"]!=0].reset_index(drop=True)\n",
    "p_valid = train[train[\"kfold\"]==0].reset_index(drop=True)\n",
    "p_test=test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b205e33",
   "metadata": {
    "papermill": {
     "duration": 0.007862,
     "end_time": "2024-12-23T03:49:06.270862",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.263000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "'token_type_ids' no need in RoBERTa/DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fb37784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.287870Z",
     "iopub.status.busy": "2024-12-23T03:49:06.287584Z",
     "iopub.status.idle": "2024-12-23T03:49:06.292722Z",
     "shell.execute_reply": "2024-12-23T03:49:06.291951Z"
    },
    "papermill": {
     "duration": 0.015003,
     "end_time": "2024-12-23T03:49:06.294030",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.279027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class BERTDataSet(Dataset):\n",
    "    \n",
    "    def __init__(self,sentences,targets):        \n",
    "        self.sentences = sentences\n",
    "        self.targets = targets\n",
    "        \n",
    "    def __len__(self):        \n",
    "        return len(self.sentences)\n",
    "    \n",
    "    def __getitem__(self,idx):        \n",
    "        sentence = self.sentences[idx]    \n",
    "        bert_sens = tokenizer.encode_plus(\n",
    "                                sentence,\n",
    "                                add_special_tokens = True, \n",
    "                                max_length = max_sens, \n",
    "                                pad_to_max_length = True, \n",
    "                                return_attention_mask = True)\n",
    "\n",
    "        ids = torch.tensor(bert_sens['input_ids'], dtype=torch.long)\n",
    "        mask = torch.tensor(bert_sens['attention_mask'], dtype=torch.long)\n",
    "\n",
    "        target = torch.tensor(self.targets[idx],dtype=torch.float)\n",
    "        \n",
    "        return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': target\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cfaac4c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.311065Z",
     "iopub.status.busy": "2024-12-23T03:49:06.310826Z",
     "iopub.status.idle": "2024-12-23T03:49:06.315599Z",
     "shell.execute_reply": "2024-12-23T03:49:06.314975Z"
    },
    "papermill": {
     "duration": 0.014699,
     "end_time": "2024-12-23T03:49:06.316869",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.302170",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
    "valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
    "test_dataset = BERTDataSet(p_test[\"text\"],p_test['targets'])\n",
    "\n",
    "train_batch = 16\n",
    "valid_batch = 32\n",
    "test_batch = 32\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=8,pin_memory=True)\n",
    "valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=8,pin_memory=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=test_batch,shuffle = False,num_workers=8,pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bc947c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:43:29.726185Z",
     "iopub.status.busy": "2024-12-23T03:43:29.725902Z",
     "iopub.status.idle": "2024-12-23T03:43:29.986784Z",
     "shell.execute_reply": "2024-12-23T03:43:29.985808Z",
     "shell.execute_reply.started": "2024-12-23T03:43:29.726157Z"
    },
    "papermill": {
     "duration": 0.007847,
     "end_time": "2024-12-23T03:49:06.332750",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.324903",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# num_labels=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f3cee76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:06.349749Z",
     "iopub.status.busy": "2024-12-23T03:49:06.349553Z",
     "iopub.status.idle": "2024-12-23T03:49:15.918772Z",
     "shell.execute_reply": "2024-12-23T03:49:15.917948Z"
    },
    "papermill": {
     "duration": 9.579171,
     "end_time": "2024-12-23T03:49:15.920043",
     "exception": false,
     "start_time": "2024-12-23T03:49:06.340872",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c75e39a68864e3da4e328d7cdcc4982",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "\n",
    "#model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=1)\n",
    "#model = transformers.BertForSequenceClassification.from_pretrained(\"../input/bert-base-uncased\",num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f6158b73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:15.938580Z",
     "iopub.status.busy": "2024-12-23T03:49:15.938094Z",
     "iopub.status.idle": "2024-12-23T03:49:16.344281Z",
     "shell.execute_reply": "2024-12-23T03:49:16.343500Z"
    },
    "papermill": {
     "duration": 0.416485,
     "end_time": "2024-12-23T03:49:16.345599",
     "exception": false,
     "start_time": "2024-12-23T03:49:15.929114",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49133d73",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:16.363720Z",
     "iopub.status.busy": "2024-12-23T03:49:16.363461Z",
     "iopub.status.idle": "2024-12-23T03:49:17.260623Z",
     "shell.execute_reply": "2024-12-23T03:49:17.259735Z"
    },
    "papermill": {
     "duration": 0.907872,
     "end_time": "2024-12-23T03:49:17.262311",
     "exception": false,
     "start_time": "2024-12-23T03:49:16.354439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "for a in train_dataloader:\n",
    "    ids = a[\"ids\"].to(device)\n",
    "    mask = a[\"mask\"].to(device)\n",
    "    output = model(ids,mask)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e20bea85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.281617Z",
     "iopub.status.busy": "2024-12-23T03:49:17.281350Z",
     "iopub.status.idle": "2024-12-23T03:49:17.289385Z",
     "shell.execute_reply": "2024-12-23T03:49:17.288781Z"
    },
    "papermill": {
     "duration": 0.018677,
     "end_time": "2024-12-23T03:49:17.290763",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.272086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output = output[\"logits\"].squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5166c0d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.309128Z",
     "iopub.status.busy": "2024-12-23T03:49:17.308875Z",
     "iopub.status.idle": "2024-12-23T03:49:17.784132Z",
     "shell.execute_reply": "2024-12-23T03:49:17.783234Z"
    },
    "papermill": {
     "duration": 0.486225,
     "end_time": "2024-12-23T03:49:17.785778",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.299553",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "LR=2e-5\n",
    "optimizer = AdamW(model.parameters(), LR,betas=(0.9,0.999), weight_decay=1e-2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ef146b4d",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.805926Z",
     "iopub.status.busy": "2024-12-23T03:49:17.805664Z",
     "iopub.status.idle": "2024-12-23T03:49:17.809886Z",
     "shell.execute_reply": "2024-12-23T03:49:17.808981Z"
    },
    "papermill": {
     "duration": 0.014977,
     "end_time": "2024-12-23T03:49:17.811252",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.796275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "595\n"
     ]
    }
   ],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "epochs = 10\n",
    "train_steps = int(len(p_train)/train_batch*epochs)\n",
    "print(train_steps)\n",
    "num_steps = int(train_steps*0.1)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6620cded",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.829272Z",
     "iopub.status.busy": "2024-12-23T03:49:17.829064Z",
     "iopub.status.idle": "2024-12-23T03:49:17.832008Z",
     "shell.execute_reply": "2024-12-23T03:49:17.831414Z"
    },
    "papermill": {
     "duration": 0.013236,
     "end_time": "2024-12-23T03:49:17.833257",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.820021",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def loss_fn(output,target):\n",
    "    return torch.sqrt(nn.MSELoss()(output,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0e585",
   "metadata": {
    "papermill": {
     "duration": 0.008372,
     "end_time": "2024-12-23T03:49:17.850467",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.842095",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "88fc3c7b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.868319Z",
     "iopub.status.busy": "2024-12-23T03:49:17.868104Z",
     "iopub.status.idle": "2024-12-23T03:49:17.875055Z",
     "shell.execute_reply": "2024-12-23T03:49:17.874429Z"
    },
    "papermill": {
     "duration": 0.017168,
     "end_time": "2024-12-23T03:49:17.876172",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.859004",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training(\n",
    "    train_dataloader,\n",
    "    model,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    device=None,  # Default device set to None\n",
    "    scaler=None,  # Default scaler set to None\n",
    "    loss_fn=None,  # Default loss_fn set to None\n",
    "    verbose=False\n",
    "):\n",
    "    # Set default values if not passed\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if scaler is None:\n",
    "        scaler = torch.cuda.amp.GradScaler()  # For mixed precision training\n",
    "    if loss_fn is None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()  # Example loss function\n",
    "    \n",
    "    model.train()\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "\n",
    "    for a in train_dataloader:\n",
    "        losses = []\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "\n",
    "            ids = a[\"ids\"].to(device, non_blocking=True)\n",
    "            mask = a[\"mask\"].to(device, non_blocking=True)\n",
    "\n",
    "            output = model(ids, mask)\n",
    "            output = output[\"logits\"].squeeze(-1)  \n",
    "\n",
    "            target = a[\"targets\"].to(device, non_blocking=True)\n",
    "            target = target.long() \n",
    "            \n",
    "            output = output.view(-1, 4) \n",
    "            target = target.view(-1)\n",
    "\n",
    "            #print('output.shape', output.shape)\n",
    "            #print('target.shape', target.shape)   \n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predicted_class = torch.argmax(output, dim=-1)  \n",
    "\n",
    "            allpreds.append(predicted_class.detach().cpu().numpy())  \n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())  \n",
    "\n",
    "        scaler.scale(loss).backward() \n",
    "        scaler.step(optimizer) \n",
    "        scaler.update() \n",
    "        \n",
    "        del loss \n",
    "\n",
    "        scheduler.step() \n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    train_rme_loss = np.sqrt(mean_squared_error(alltargets, allpreds))\n",
    "\n",
    "    return losses, train_rme_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984b1bc",
   "metadata": {
    "papermill": {
     "duration": 0.008458,
     "end_time": "2024-12-23T03:49:17.893213",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.884755",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "082202b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.911770Z",
     "iopub.status.busy": "2024-12-23T03:49:17.911569Z",
     "iopub.status.idle": "2024-12-23T03:49:17.917536Z",
     "shell.execute_reply": "2024-12-23T03:49:17.916938Z"
    },
    "papermill": {
     "duration": 0.016506,
     "end_time": "2024-12-23T03:49:17.918635",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.902129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validating(valid_dataloader, model, device=None, loss_fn=None):\n",
    "    # Set default values if not passed\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if loss_fn is None:\n",
    "        loss_fn = torch.nn.CrossEntropyLoss()  # Example loss function\n",
    "\n",
    "    model.eval()\n",
    "    allpreds = []\n",
    "    alltargets = []\n",
    "    losses = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a in valid_dataloader:\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids, mask)\n",
    "            output = output[\"logits\"].squeeze(-1)  # Adjust according to model output\n",
    "\n",
    "            target = a[\"targets\"].to(device, non_blocking=True)\n",
    "            target = target.long()           \n",
    "\n",
    "            output = output.view(-1, 4)  # Adjust if necessary\n",
    "            target = target.view(-1)\n",
    "\n",
    "            #print('output.shape', output.shape)\n",
    "            #print('target.shape', target.shape)\n",
    "\n",
    "            loss = loss_fn(output, target)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            predicted_class = torch.argmax(output, dim=-1)  # Predicted class from logits\n",
    "\n",
    "            allpreds.append(predicted_class.detach().cpu().numpy())\n",
    "            alltargets.append(target.detach().squeeze(-1).cpu().numpy())\n",
    "\n",
    "            del loss  # To avoid unnecessary memory usage\n",
    "\n",
    "    allpreds = np.concatenate(allpreds)\n",
    "    alltargets = np.concatenate(alltargets)\n",
    "    losses = np.mean(losses)\n",
    "    valid_rmse_loss = np.sqrt(mean_squared_error(alltargets, allpreds))\n",
    "\n",
    "    return allpreds, losses, valid_rmse_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0becf314",
   "metadata": {
    "papermill": {
     "duration": 0.008497,
     "end_time": "2024-12-23T03:49:17.935915",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.927418",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# training and validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60e702af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:49:17.953866Z",
     "iopub.status.busy": "2024-12-23T03:49:17.953666Z",
     "iopub.status.idle": "2024-12-23T03:50:14.975345Z",
     "shell.execute_reply": "2024-12-23T03:50:14.974295Z"
    },
    "papermill": {
     "duration": 57.032237,
     "end_time": "2024-12-23T03:50:14.976805",
     "exception": false,
     "start_time": "2024-12-23T03:49:17.944568",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.7650566488832735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.8601750041394236\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:07<01:11,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.7168384032381028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1222362611952184\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:16<01:06,  8.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.3300940013645266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:21<00:48,  6.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2425510268770878\n",
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0738716961197818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:26<00:36,  6.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2790556139583322\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8340850055194129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:31<00:28,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2609354301453408\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.6188707856394122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:36<00:22,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1388903062661975\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.46153173509237333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:41<00:16,  5.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1821546175306148\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.3366397746559039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:46<00:10,  5.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2101384823413865\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24023423337136135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:52<00:05,  5.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1480381665254702\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.14119858683216271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:57<00:00,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2341039471216577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainlosses = []\n",
    "vallosses = []\n",
    "bestscore = None\n",
    "trainscores = []\n",
    "validscores = []\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    \n",
    "    print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "    \n",
    "    trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)    \n",
    "    trainlosses.append(trainloss)\n",
    "    trainscores.append(trainscore)\n",
    "    \n",
    "    print(\"trainscore is \" + str(trainscore))\n",
    "    \n",
    "    preds,validloss,valscore=validating(valid_dataloader,model)    \n",
    "    vallosses.append(validloss)\n",
    "    validscores.append(valscore)\n",
    "    \n",
    "    print(\"valscore is \" + str(valscore))\n",
    "    \n",
    "    if bestscore is None:\n",
    "        bestscore = valscore\n",
    "        \n",
    "        print(\"Save first model\")\n",
    "        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")\n",
    "        \n",
    "    elif bestscore > valscore:\n",
    "        \n",
    "        bestscore = valscore        \n",
    "        print(\"found better point\")        \n",
    "        state = {\n",
    "                        'state_dict': model.state_dict(),\n",
    "                        'optimizer_dict': optimizer.state_dict(),\n",
    "                        \"bestscore\":bestscore\n",
    "                    }\n",
    "            \n",
    "        torch.save(state, \"model0.pth\")\n",
    "        \n",
    "    else:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f4cdb30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:50:15.018622Z",
     "iopub.status.busy": "2024-12-23T03:50:15.018370Z",
     "iopub.status.idle": "2024-12-23T03:50:15.627289Z",
     "shell.execute_reply": "2024-12-23T03:50:15.626290Z"
    },
    "papermill": {
     "duration": 0.629457,
     "end_time": "2024-12-23T03:50:15.628585",
     "exception": false,
     "start_time": "2024-12-23T03:50:14.999128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(p_valid['targets'],preds, alpha=0.2)\n",
    "plt.title('Validation Prediction Result')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.plot(x,trainlosses)\n",
    "plt.plot(x,vallosses)\n",
    "plt.show()\n",
    "\n",
    "x = np.arange(epochs)\n",
    "plt.title('Validation Scores')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.plot(x,trainscores)\n",
    "plt.plot(x,validscores)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7d55dfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:50:15.667722Z",
     "iopub.status.busy": "2024-12-23T03:50:15.667455Z",
     "iopub.status.idle": "2024-12-23T03:50:15.681236Z",
     "shell.execute_reply": "2024-12-23T03:50:15.680268Z"
    },
    "papermill": {
     "duration": 0.034506,
     "end_time": "2024-12-23T03:50:15.682640",
     "exception": false,
     "start_time": "2024-12-23T03:50:15.648134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 0, 0, 0, 2, 0, 0, 2, 1, 0, 0, 3, 0, 1, 0, 0, 2, 2, 0, 0, 1, 0, 0, 0, 3, 0, 0, 0, 0, 2, 2, 3, 2, 2, 0, 0, 0, 0, 3, 3, 1, 0, 2, 0, 0, 1, 0, 0, 1, 1, 3, 0, 1, 0, 0, 1, 2, 0, 1, 3, 1, 1, 3, 1, 3, 1, 1, 0, 3, 3, 0, 0, 0, 1, 0, 1, 1, 0, 2, 1, 2, 2, 0, 1, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 0, 2, 1, 3, 3, 0, 1, 1, 2, 3, 1, 3, 1, 1, 3, 3, 3, 1, 1, 0, 3, 1, 2, 0, 1, 1, 2, 2, 0, 2, 2, 3, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 3, 1, 2, 2, 0, 2, 1, 0, 1, 2, 2, 2, 2, 3, 3, 3, 1, 1, 0, 3, 1, 1, 3, 0, 3, 2, 0, 3, 2, 3, 1, 3, 3, 3, 1, 3, 3, 1, 0, 3, 3, 0, 3, 1, 2, 2, 0, 2, 3, 3, 2, 1, 3, 3, 3, 1, 1, 3, 3, 0, 2, 0, 3, 3, 3, 3, 2, 3, 3, 3, 0, 3, 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false     0.5614    0.5333    0.5470        60\n",
      "   non-rumor     0.5283    0.4590    0.4912        61\n",
      "        true     0.6338    0.7759    0.6977        58\n",
      "  unverified     0.5345    0.5167    0.5254        60\n",
      "\n",
      "    accuracy                         0.5690       239\n",
      "   macro avg     0.5645    0.5712    0.5653       239\n",
      "weighted avg     0.5638    0.5690    0.5639       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "val_true = p_valid['targets']\n",
    "val_pred = []\n",
    "for p in preds:\n",
    "    val_pred+=[p]\n",
    "print(val_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(val_true,val_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f37fe",
   "metadata": {
    "papermill": {
     "duration": 0.018848,
     "end_time": "2024-12-23T03:50:15.720391",
     "exception": false,
     "start_time": "2024-12-23T03:50:15.701543",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6b83229",
   "metadata": {
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2024-12-23T03:50:15.759540Z",
     "iopub.status.busy": "2024-12-23T03:50:15.759320Z",
     "iopub.status.idle": "2024-12-23T03:54:31.212519Z",
     "shell.execute_reply": "2024-12-23T03:54:31.211335Z"
    },
    "papermill": {
     "duration": 255.474061,
     "end_time": "2024-12-23T03:54:31.213747",
     "exception": false,
     "start_time": "2024-12-23T03:50:15.739686",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.6643915916662262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2238904974673164\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:07<01:03,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.505498840121624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.160724056237327\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:15<01:02,  7.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.2871958019387946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:20<00:45,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2153137239818963\n",
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.9878591434527763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:24<00:34,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2872077399123953\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.6833348262637357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:29<00:26,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2823226834284522\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.40459065629416807\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1407257471125665\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:37<00:25,  6.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.35187997572147534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1240988952756037\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:46<00:21,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.27865664859630657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:50<00:12,  6.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1786099180441907\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.23582589127755257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:55<00:05,  5.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1909702103079673\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15535222140911636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:00<00:00,  6.05s/it]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1856887199369714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.7513097823852886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.861823448832313\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:06<01:02,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.5821329445049965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.307701813722626\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:14<01:00,  7.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.329002400093742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2685596940936565\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:23<00:56,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0217754925778482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2178642277819496\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:31<00:48,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7736488187536448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:36<00:34,  6.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2485285456935955\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.48672094123134224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:41<00:24,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2213093951392753\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.29673273237950815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1846355323633573\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:49<00:20,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.31722063428725766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:54<00:12,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.226459000811796\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24656975828820954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:59<00:05,  5.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.210944488662403\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.15185781720314007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1757350641945108\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:07<00:00,  6.79s/it]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.4970271028777415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.8663315025233123\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:07<01:05,  7.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.4843700002674267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.4609769955453114\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:15<01:03,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.299491918129166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2996444245454604\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:24<00:57,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.0385645633282785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:29<00:41,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.307701813722626\n",
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.8279701632274973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2315870747491122\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:37<00:37,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5863578375248636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1208490179361372\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:46<00:31,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.3871629866052087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0749242693668934\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:54<00:23,  7.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.37478155762112153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:59<00:13,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0865874419058794\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.24656975828820954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [01:04<00:06,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.0904474449748143\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.2171861213815347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:08<00:00,  6.89s/it]\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1320391358261501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------0start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.781573515988638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.7271923104596443\n",
      "Save first model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|‚ñà         | 1/10 [00:06<01:02,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------1start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.6776368524817973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2349939611324476\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|‚ñà‚ñà        | 2/10 [00:15<01:02,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------2start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 1.2501572228167968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 30%|‚ñà‚ñà‚ñà       | 3/10 [00:20<00:45,  6.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.2980269448589394\n",
      "---------------3start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.9577007756503811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1245914290767742\n",
      "found better point\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 4/10 [00:28<00:42,  7.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------4start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.7048796676823283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [00:33<00:31,  6.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1613524425420216\n",
      "---------------5start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.5319951765989315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [00:37<00:23,  5.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1577288691458727\n",
      "---------------6start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.3221390769615825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [00:42<00:16,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1559128227429232\n",
      "---------------7start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.30371563440628013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [00:47<00:10,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1739468729479208\n",
      "---------------8start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.27280667162636885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      " 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [00:52<00:05,  5.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1952286093343936\n",
      "---------------9start-------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainscore is 0.17733172553297716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:56<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valscore is 1.1685658811070068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bestscores = []\n",
    "bestscores.append(bestscore)\n",
    "\n",
    "for fold in range(1,5):\n",
    "    \n",
    "    # initializing the data\n",
    "    p_train = train[train[\"kfold\"]!=fold].reset_index(drop=True)\n",
    "    p_valid = train[train[\"kfold\"]==fold].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BERTDataSet(p_train[\"text\"],p_train['targets'])\n",
    "    valid_dataset = BERTDataSet(p_valid[\"text\"],p_valid['targets'])\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset,batch_size=train_batch,shuffle = True,num_workers=4,pin_memory=True)\n",
    "    valid_dataloader = DataLoader(valid_dataset,batch_size=valid_batch,shuffle = False,num_workers=4,pin_memory=True)\n",
    "\n",
    "    model = transformers.RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n",
    "\n",
    "    model.to(device)\n",
    "    LR=2e-5\n",
    "    optimizer = AdamW(model.parameters(), LR,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n",
    "    train_steps = int(len(p_train)/train_batch*epochs)\n",
    "    num_steps = int(train_steps*0.1)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n",
    "\n",
    "    trainlosses = []\n",
    "    vallosses = []\n",
    "    bestscore = None\n",
    "    trainscores = []\n",
    "    validscores = []\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "\n",
    "        print(\"---------------\" + str(epoch) + \"start-------------\")\n",
    "\n",
    "        trainloss,trainscore = training(train_dataloader,model,optimizer,scheduler)\n",
    "        trainlosses.append(trainloss)\n",
    "        trainscores.append(trainscore)\n",
    "\n",
    "        print(\"trainscore is \" + str(trainscore))\n",
    "\n",
    "        preds,validloss,valscore=validating(valid_dataloader,model)\n",
    "        vallosses.append(validloss)\n",
    "        validscores.append(valscore)\n",
    "\n",
    "        print(\"valscore is \" + str(valscore))\n",
    "\n",
    "        if bestscore is None:\n",
    "            bestscore = valscore\n",
    "\n",
    "            print(\"Save first model\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "\n",
    "            torch.save(state, \"model\" + str(fold) + \".pth\") \n",
    "\n",
    "        elif bestscore > valscore:\n",
    "            bestscore = valscore\n",
    "            print(\"found better point\")\n",
    "\n",
    "            state = {\n",
    "                            'state_dict': model.state_dict(),\n",
    "                            'optimizer_dict': optimizer.state_dict(),\n",
    "                            \"bestscore\":bestscore\n",
    "                        }\n",
    "            torch.save(state, \"model\"+ str(fold) + \".pth\")\n",
    "\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "    bestscores.append(bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1cb74f82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:54:31.299019Z",
     "iopub.status.busy": "2024-12-23T03:54:31.298715Z",
     "iopub.status.idle": "2024-12-23T03:54:31.304191Z",
     "shell.execute_reply": "2024-12-23T03:54:31.303342Z"
    },
    "papermill": {
     "duration": 0.049477,
     "end_time": "2024-12-23T03:54:31.305394",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.255917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1222362611952184,\n",
       " 1.1240988952756037,\n",
       " 1.1757350641945108,\n",
       " 1.0749242693668934,\n",
       " 1.1245914290767742]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0b66ab97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:54:31.387716Z",
     "iopub.status.busy": "2024-12-23T03:54:31.387471Z",
     "iopub.status.idle": "2024-12-23T03:54:31.391832Z",
     "shell.execute_reply": "2024-12-23T03:54:31.390921Z"
    },
    "papermill": {
     "duration": 0.046577,
     "end_time": "2024-12-23T03:54:31.393236",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.346659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv = 1.1243171838218\n"
     ]
    }
   ],
   "source": [
    "np.mean(bestscores)\n",
    "print(\"cv = \" + str(np.mean(bestscores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48648c7c",
   "metadata": {
    "papermill": {
     "duration": 0.041457,
     "end_time": "2024-12-23T03:54:31.475560",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.434103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# def predicting\n",
    "not use saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "839c5e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:54:31.557508Z",
     "iopub.status.busy": "2024-12-23T03:54:31.557246Z",
     "iopub.status.idle": "2024-12-23T03:54:31.562055Z",
     "shell.execute_reply": "2024-12-23T03:54:31.561240Z"
    },
    "papermill": {
     "duration": 0.04695,
     "end_time": "2024-12-23T03:54:31.563269",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.516319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predicting(test_dataloader,model):\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()   \n",
    "    allpreds = []\n",
    "    preds = []\n",
    "    allvalloss=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for a in test_dataloader:\n",
    "\n",
    "            ids = a[\"ids\"].to(device)\n",
    "            mask = a[\"mask\"].to(device)\n",
    "\n",
    "            output = model(ids,mask)\n",
    "            output = output[\"logits\"].squeeze(-1)\n",
    "            preds.append(output.cpu().numpy())\n",
    "\n",
    "        preds = np.concatenate(preds)\n",
    "        allpreds.append(preds)\n",
    "\n",
    "    return allpreds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905533c5",
   "metadata": {
    "papermill": {
     "duration": 0.040805,
     "end_time": "2024-12-23T03:54:31.645294",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.604489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ef3ab057",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:54:31.731880Z",
     "iopub.status.busy": "2024-12-23T03:54:31.731635Z",
     "iopub.status.idle": "2024-12-23T03:54:32.306326Z",
     "shell.execute_reply": "2024-12-23T03:54:32.305155Z"
    },
    "papermill": {
     "duration": 0.62114,
     "end_time": "2024-12-23T03:54:32.308156",
     "exception": false,
     "start_time": "2024-12-23T03:54:31.687016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "tpreds = predicting(test_dataloader,model)\n",
    "#tpreds = predicting2(test_dataloader,model,pthes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04196f36",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T03:54:32.393044Z",
     "iopub.status.busy": "2024-12-23T03:54:32.392725Z",
     "iopub.status.idle": "2024-12-23T03:54:32.406548Z",
     "shell.execute_reply": "2024-12-23T03:54:32.405636Z"
    },
    "papermill": {
     "duration": 0.056761,
     "end_time": "2024-12-23T03:54:32.407673",
     "exception": false,
     "start_time": "2024-12-23T03:54:32.350912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 2, 1, 2, 1, 3, 3, 1, 0, 2, 1, 3, 1, 3, 3, 2, 0, 0, 2, 2, 3, 1, 0, 0, 2, 3, 0, 0, 2, 3, 3, 1, 1, 3, 3, 2, 1, 0, 1, 3, 2, 3, 0, 3, 1, 3, 3, 3, 0, 0, 3, 3, 1, 3, 3, 3, 0, 1, 0, 0, 3, 2, 3, 3, 2, 3, 1, 0, 0, 3, 3, 3, 3, 0, 0, 1, 3, 3, 1, 3, 0, 1, 2, 3, 0, 2, 2, 1, 2, 2, 3, 0, 1, 3, 2, 2, 1, 1, 0, 2, 3, 2, 0, 0, 2, 3, 3, 1, 1, 0, 3, 0, 2, 3, 0, 2, 3, 2, 1, 3, 2, 1, 0, 2, 1, 1, 3, 2, 1, 2, 3, 2, 1, 2, 0, 3, 3, 2, 2, 1, 2, 2, 2, 0, 1, 3, 2, 3, 2, 3, 1, 3, 1, 3, 0, 1, 2, 2, 0, 0, 2, 3, 2, 2, 2, 3, 1, 2, 2, 3, 2, 1, 2, 3, 2, 0, 0, 1, 2, 3, 2, 0, 2, 2, 1, 2, 3, 0, 3, 1, 2, 0, 1, 3, 2, 0, 1, 0, 1, 2, 0, 1, 1, 0, 0, 3, 3, 2, 1, 0, 2, 2, 1, 0, 2, 0, 0, 2, 1, 3, 2, 0, 1, 2, 3, 2, 2, 2, 0, 0, 3, 0, 1, 0, 2, 2, 1, 2, 2, 2, 2, 1, 0, 2, 0, 2, 2, 0, 3, 0, 2, 1, 1, 3, 0, 3, 0, 2, 2, 0, 2, 2, 0, 0, 1, 1, 3, 0, 0, 3, 0, 3, 2, 0, 1, 2, 2, 3, 0, 0, 2, 3, 2, 0, 1, 1, 0, 2, 0, 0, 1, 2, 1, 3, 2, 3, 1, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       false     0.6056    0.6056    0.6056        71\n",
      "   non-rumor     0.5574    0.4928    0.5231        69\n",
      "        true     0.6778    0.7262    0.7011        84\n",
      "  unverified     0.4868    0.5000    0.4933        74\n",
      "\n",
      "    accuracy                         0.5872       298\n",
      "   macro avg     0.5819    0.5811    0.5808       298\n",
      "weighted avg     0.5853    0.5872    0.5856       298\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_true = p_test['targets']\n",
    "test_pred = []\n",
    "for p in tpreds[0]:\n",
    "    test_pred+=[np.argmax(p)]\n",
    "print(test_pred)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(test_true,test_pred,target_names=class_names,digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fb2ccb",
   "metadata": {
    "papermill": {
     "duration": 0.042934,
     "end_time": "2024-12-23T03:54:32.491885",
     "exception": false,
     "start_time": "2024-12-23T03:54:32.448951",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6257637,
     "sourceId": 10139125,
     "sourceType": "datasetVersion"
    }
   ],
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 353.032716,
   "end_time": "2024-12-23T03:54:35.300188",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-23T03:48:42.267472",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "01cb746419fe4e6a910c3a4606537e26": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "0260d3715c304d8a8861b9476ec58233": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_309ce1981b0e49b3981cf81ab01f6786",
       "max": 481,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d8a79cd41b6e428e8fb3af12c320a2e3",
       "tabbable": null,
       "tooltip": null,
       "value": 481
      }
     },
     "0fec18e0a7fc4dba9f478180fec5f697": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_99707cbdd2da4421ae96901954c9c898",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_f4a06bfc97bc432780006b614c23ac5d",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json:‚Äá100%"
      }
     },
     "10d18d8df7894ee185ad03d426c82943": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "14b49606917c470ca8c0c83921f093ea": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "154465ad68cf4043aed662145ddbb3c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18fee7cb30694f18b2db88c29fefe6cc": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "1ba20c09ced543938820e6eeebd8f380": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_14b49606917c470ca8c0c83921f093ea",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_9c4b57eb339c4a7cb43886d226dfd711",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json:‚Äá100%"
      }
     },
     "26043b34c2394b078db8752d6980cf80": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_65653555126f44d8b218b18917ceb48c",
       "max": 898823,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_d771891cb0c24da79b20f46b187c11bb",
       "tabbable": null,
       "tooltip": null,
       "value": 898823
      }
     },
     "2758f1bbcebc4a7ba240449903129bc6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2d781c27ded04a648cd73b52add6b9d1",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_3864acc799784f7f88bc2656bf2f7caf",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá499M/499M‚Äá[00:08&lt;00:00,‚Äá62.9MB/s]"
      }
     },
     "2a29a243668f465dae708ca1f205c9ff": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f2b828bf4a454387ab566c344a1fd743",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_bd80fe7d3d8f4e9bacedcdb9cba6bca7",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá1.36M/1.36M‚Äá[00:00&lt;00:00,‚Äá15.9MB/s]"
      }
     },
     "2c882a3d35ef435f8498a242aecaa08a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2c9dfca9edf84560a731a30e0de9b96f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_64e9db5965904fe89210fa73cba340ba",
        "IPY_MODEL_0260d3715c304d8a8861b9476ec58233",
        "IPY_MODEL_cc3332b258644404bbd3212ce5768bd9"
       ],
       "layout": "IPY_MODEL_8f4e199996774a5bb9a49a0b12e7bc1d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "2d781c27ded04a648cd73b52add6b9d1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "309ce1981b0e49b3981cf81ab01f6786": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "344fd4883dee4e5180a0b38cfdc135b8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3864acc799784f7f88bc2656bf2f7caf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "403cc1a3505c439b9ae11e17f04f5c59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_c7ccab599acc4c91a1512c5bd5e561fb",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_79b2c5b4a7474330aa6056f9b2c3fc2c",
       "tabbable": null,
       "tooltip": null,
       "value": 25
      }
     },
     "40a52ae336fc457d8c313e764dfe2157": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_90d74d33442242ea9e73eb8469b751c2",
       "max": 456318,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_60edfe08bc5b4887af667a7f9b1dcc4b",
       "tabbable": null,
       "tooltip": null,
       "value": 456318
      }
     },
     "44cf688d950544a6b31f197ef151fd4d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b2771611f9d64d09a2e44ddba6890c16",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_7f694b790cdd41ab8cd3755c4a0d4652",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá899k/899k‚Äá[00:00&lt;00:00,‚Äá12.0MB/s]"
      }
     },
     "58d9d2d5c4bd4c29b90a63c64998eb1e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ab681cf1673435a8979ad0249c605ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5baab0970c19431fb7737772e6afc690": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "60edfe08bc5b4887af667a7f9b1dcc4b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "62878946f13c478b9aa090efe62cf7d9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_1ba20c09ced543938820e6eeebd8f380",
        "IPY_MODEL_a1785881c0f846128025cb03504d3507",
        "IPY_MODEL_2a29a243668f465dae708ca1f205c9ff"
       ],
       "layout": "IPY_MODEL_e5681799c32f40d789693881e9a92268",
       "tabbable": null,
       "tooltip": null
      }
     },
     "64e9db5965904fe89210fa73cba340ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_efa1b392a4bf46808e72155e0a84d1fa",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_58d9d2d5c4bd4c29b90a63c64998eb1e",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json:‚Äá100%"
      }
     },
     "65653555126f44d8b218b18917ceb48c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6fcae520542c470190261ad6f387ed01": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "74d26ed9dc514f49975dcca4c02b2df4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "7846800b399b4fe0bf6646c556419a2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a7a2ae1b63234ca5b86946c3bbaaea5f",
        "IPY_MODEL_26043b34c2394b078db8752d6980cf80",
        "IPY_MODEL_44cf688d950544a6b31f197ef151fd4d"
       ],
       "layout": "IPY_MODEL_f3eed214577d4b5a9e9305fb8db21285",
       "tabbable": null,
       "tooltip": null
      }
     },
     "79b2c5b4a7474330aa6056f9b2c3fc2c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7f694b790cdd41ab8cd3755c4a0d4652": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "81e2723ad1a045338fc56936a50724b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8f4e199996774a5bb9a49a0b12e7bc1d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90d74d33442242ea9e73eb8469b751c2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "915928f72f314950bda5f1264277793d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_154465ad68cf4043aed662145ddbb3c2",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_18fee7cb30694f18b2db88c29fefe6cc",
       "tabbable": null,
       "tooltip": null,
       "value": "merges.txt:‚Äá100%"
      }
     },
     "91cacf0ebb4a4a94a93b9a659adf7724": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "99707cbdd2da4421ae96901954c9c898": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9c4b57eb339c4a7cb43886d226dfd711": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9c75e39a68864e3da4e328d7cdcc4982": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c3b36a2086274ceca0739756bf575a04",
        "IPY_MODEL_b6127d0e1124499db5cb1ff81df0bd3f",
        "IPY_MODEL_2758f1bbcebc4a7ba240449903129bc6"
       ],
       "layout": "IPY_MODEL_10d18d8df7894ee185ad03d426c82943",
       "tabbable": null,
       "tooltip": null
      }
     },
     "a1785881c0f846128025cb03504d3507": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_dd10b65a80a4440fb185665a8523d7ff",
       "max": 1355863,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_344fd4883dee4e5180a0b38cfdc135b8",
       "tabbable": null,
       "tooltip": null,
       "value": 1355863
      }
     },
     "a6ef536085cf4690a95c7fbeca9b9fc3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7a2ae1b63234ca5b86946c3bbaaea5f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_01cb746419fe4e6a910c3a4606537e26",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_efdad56e6aec4b418539667b7bc85bb4",
       "tabbable": null,
       "tooltip": null,
       "value": "vocab.json:‚Äá100%"
      }
     },
     "b2771611f9d64d09a2e44ddba6890c16": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b6127d0e1124499db5cb1ff81df0bd3f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2c882a3d35ef435f8498a242aecaa08a",
       "max": 498818054,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f2b9b994dd534197b784ffce4bc4bbfa",
       "tabbable": null,
       "tooltip": null,
       "value": 498818054
      }
     },
     "b7d1dc4add5f45f8b78ff8a5558758e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_91cacf0ebb4a4a94a93b9a659adf7724",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_c71a150cf0e9468aa539bcaf11c7be89",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá25.0/25.0‚Äá[00:00&lt;00:00,‚Äá2.42kB/s]"
      }
     },
     "b93821c7212d4084ade0dbbd0de42eca": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_0fec18e0a7fc4dba9f478180fec5f697",
        "IPY_MODEL_403cc1a3505c439b9ae11e17f04f5c59",
        "IPY_MODEL_b7d1dc4add5f45f8b78ff8a5558758e8"
       ],
       "layout": "IPY_MODEL_db02a864841f438eb54af0623274738b",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bad2a4875ea449f1b33e33026229a370": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_915928f72f314950bda5f1264277793d",
        "IPY_MODEL_40a52ae336fc457d8c313e764dfe2157",
        "IPY_MODEL_f9327e1c45a941d1b12b056dcf294b48"
       ],
       "layout": "IPY_MODEL_6fcae520542c470190261ad6f387ed01",
       "tabbable": null,
       "tooltip": null
      }
     },
     "bd80fe7d3d8f4e9bacedcdb9cba6bca7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c3b36a2086274ceca0739756bf575a04": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_a6ef536085cf4690a95c7fbeca9b9fc3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_d6a51a5bf7924b70b29c613e757e2eee",
       "tabbable": null,
       "tooltip": null,
       "value": "model.safetensors:‚Äá100%"
      }
     },
     "c71a150cf0e9468aa539bcaf11c7be89": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "c7ccab599acc4c91a1512c5bd5e561fb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "cc3332b258644404bbd3212ce5768bd9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_81e2723ad1a045338fc56936a50724b3",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_74d26ed9dc514f49975dcca4c02b2df4",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá481/481‚Äá[00:00&lt;00:00,‚Äá48.5kB/s]"
      }
     },
     "d6a51a5bf7924b70b29c613e757e2eee": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d771891cb0c24da79b20f46b187c11bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "d8a79cd41b6e428e8fb3af12c320a2e3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "db02a864841f438eb54af0623274738b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "dd10b65a80a4440fb185665a8523d7ff": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e5681799c32f40d789693881e9a92268": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efa1b392a4bf46808e72155e0a84d1fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "efdad56e6aec4b418539667b7bc85bb4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f2b828bf4a454387ab566c344a1fd743": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f2b9b994dd534197b784ffce4bc4bbfa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "f3eed214577d4b5a9e9305fb8db21285": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f4a06bfc97bc432780006b614c23ac5d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f9327e1c45a941d1b12b056dcf294b48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_5baab0970c19431fb7737772e6afc690",
       "placeholder": "‚Äã",
       "style": "IPY_MODEL_5ab681cf1673435a8979ad0249c605ae",
       "tabbable": null,
       "tooltip": null,
       "value": "‚Äá456k/456k‚Äá[00:00&lt;00:00,‚Äá18.9MB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
